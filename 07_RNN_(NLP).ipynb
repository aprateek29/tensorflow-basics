{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07 RNN (NLP).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeoShsxOVNH5"
      },
      "source": [
        "### **Description**:Learn how to use RNN in Tensorflow. To use NLP (Natural Language Processing) techniques like a Tokenizer and Word Embeddings to preprocess text data, and then create a RNN model with keras to classify the tweets.\n",
        "\n",
        "\n",
        "I used a NLP Disaster Tweets dataset ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7GgNR_kvLOf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS2_oNzbvVpV"
      },
      "source": [
        "# https://www.kaggle.com/c/nlp-getting-started\n",
        "df = pd.read_csv('data/twitter_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJjrrfHDvsEz"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9zJjdn6vxzr"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaKl6-FAvx8i"
      },
      "source": [
        "print((df.target == 1).sum()) # Disaster\n",
        "print((df.target == 0).sum()) # No Disaster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tByi2X-SvyCP"
      },
      "source": [
        "# Preprocessing\n",
        "import re\n",
        "import string\n",
        "\n",
        "def remove_URL(test):\n",
        "  url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "  return url.sub(r\"\", text)\n",
        "\n",
        "# https://stackoverflow.com/questions/34293875/how-to-remove-punctuation-marks-from-a-string-in-python-3-x\n",
        "def remove_punct(text):\n",
        "  translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "  return text.translate(translator)\n",
        "\n",
        "string.punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb4aaFcDvyFq"
      },
      "source": [
        "pattern = re.compile(r\"https?://(\\S+|www)\\.\\S+\")\n",
        "for t in df.text:\n",
        "  matches = pattern.findall(t)\n",
        "  for match in matches:\n",
        "    print(t)\n",
        "    print(match)\n",
        "    print(pattern.sub(r\"\", t))\n",
        "  if len(matches) > 0:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUCIXWl6vyIq"
      },
      "source": [
        "df[\"text\"] = df.text.map(remove_URL)\n",
        "df[\"text\"] = df.text.map(remove_punct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I98mNX47vyLz"
      },
      "source": [
        "# remove stopwords\n",
        "# pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Stop words: A stop word is a commonly used word (the, an, a)\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n",
        "  return \" \".join(filtered_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9AnFuhjvyOm"
      },
      "source": [
        "stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZy8lyl3vyR1"
      },
      "source": [
        "df[\"text\"] = df.text.map(remove_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-B0umHOvyAo"
      },
      "source": [
        "df.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qv-Vso8vx5t"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count unique words\n",
        "def counter_word(text_col):\n",
        "  count = Counter()\n",
        "  for text in text_col.values:\n",
        "    for word in text.split():\n",
        "      count[word] += 1\n",
        "  return count\n",
        "\n",
        "counter = counter_word(df.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0MpQQTLvx3T"
      },
      "source": [
        "len(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSAFA_xA9gRX"
      },
      "source": [
        "counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hG5fJ-u9gp9"
      },
      "source": [
        "counter.most_common(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4AC0qZI9g3O"
      },
      "source": [
        "num_unique_words = len(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73mDpZUI9g61"
      },
      "source": [
        "# Split dataset into training and validation set\n",
        "train_size = int(df.shape[0] * .8)\n",
        "\n",
        "train_df = df[:train_size]\n",
        "val_df = df[train_size:]\n",
        "\n",
        "# split text and labels\n",
        "train_sentences = train_df.text.to_numpy()\n",
        "train_labels = train_df.target.to_numpy()\n",
        "val_sentences = val_df.text.to_numpy()\n",
        "val_labels = val_df.target.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0lo4REP9g0O"
      },
      "source": [
        "train_sentences.shape, val_sentences.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRE0_N3T9gyT"
      },
      "source": [
        "# Tokenize\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# vectorize a text corpus by turning each text into a sequence of integers\n",
        "tokenizer = Tokenizer(num_words=num_unique_words)\n",
        "tokenizer.fit_on_texts(train_sentences) # fit only to training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tScEZm6G9gu_"
      },
      "source": [
        "# each word has unique index\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s45rw_5q9gn0"
      },
      "source": [
        "word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ1mOOSP9glO"
      },
      "source": [
        "train_sequence = tokenizer.texts_to_sequences(train_sentences)\n",
        "val_sequences = tokenizer.texts_to_sequences(val_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB5GF9ws9gjI"
      },
      "source": [
        "print(train_sentences[10:15])\n",
        "print(train_sequences[10:15])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwMr-pa59ggd"
      },
      "source": [
        "# Pad the sequences to have the same length\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Max number of words in a sequence\n",
        "max_length = 20\n",
        "\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "train_padded.shape, val_padded.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az3O-d_x9geX"
      },
      "source": [
        "train_padded[10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlyR2q-d9gcS"
      },
      "source": [
        "print(train_sentences[10])\n",
        "print(train_sequences[10])\n",
        "print(train_padded[10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD7my5Zh9gaL"
      },
      "source": [
        "# check reversing the indices\n",
        "\n",
        "# flip (key, value)\n",
        "reverse_word_index = dict([(idx, word) for (word, idx) in word_index.items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8s1jBnz9gXs"
      },
      "source": [
        "reverse_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc_gYcJN9gUy"
      },
      "source": [
        "def decode(sequence):\n",
        "  return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5LeGGCQ9gPe"
      },
      "source": [
        "decoded_text = decode(train_sequences[10])\n",
        "\n",
        "print(train_sequences[10])\n",
        "print(decoded_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw2R91S19gMP"
      },
      "source": [
        "# Create LSTM model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.Embedding(num_unique_words, 32, input_length=max_length))\n",
        "\n",
        "model.add(layers.LSTM(64, dropout=.1))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkHZOrJ8FqH1"
      },
      "source": [
        "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "optim = keras.optimizers.Adam(learning_rate=0.001)\n",
        "metrics = ['accuracy']\n",
        "\n",
        "model.compile(loss=loss, optimizer=optim, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxfFKKuvFqLH"
      },
      "source": [
        "model.fit(train_padded, train_labels, epochs=20, validation_data=(val_padded, val_labels), verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kkB3u1wFqQa"
      },
      "source": [
        "predictions = model.predict(train_padded)\n",
        "predictions = [1 if p > 0.5 else 0 for p in predictions]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94GIGLkpFqTd"
      },
      "source": [
        "print(train_sentences[10:20])\n",
        "\n",
        "print(train_labels[10:20])\n",
        "print(predictions[10:20])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}